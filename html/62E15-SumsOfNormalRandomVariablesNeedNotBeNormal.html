<!DOCTYPE html><html>
<head>
<title>sums of normal random variables need not be normal</title>
<!--Generated on Sat Feb 10 12:04:17 2018 by LaTeXML (version 0.8.2) http://dlmf.nist.gov/LaTeXML/.-->

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="LaTeXML.css" type="text/css">
<link rel="stylesheet" href="ltx-article.css" type="text/css">
<link rel="stylesheet" href="https://cdn.rawgit.com/holtzermann17/3f71ceeb3b055e1ddc3b6c11fb1f074c/raw/2bb23e3b173ff96840797fc0c3bcb8c54085df8e/LaTeXML.css" type="text/css">
<link rel="stylesheet" href="https://cdn.rawgit.com/holtzermann17/4bda0365b30858ac2fb83623185fe3ec/raw/cedd84ed3e3ad597c5d293f443ecfe4803741c6b/ltx-article.css" type="text/css">
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=MML_HTMLorMML" type="text/javascript"></script>
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">sums of normal random variables need not be normal</h1>

<div id="p1" class="ltx_para">
<br class="ltx_break">
</div>
<div id="p2" class="ltx_para">
<p class="ltx_p">A common misconception among students of probability theory is the belief that the sum of two normally distributed (<span class="ltx_text ltx_font_typewriter">http://planetmath.org/NormalRandomVariable</span>) random variables is itself normally distributed. By constructing a counterexample, we show this to be false.</p>
</div>
<div id="p3" class="ltx_para">
<p class="ltx_p">It is however well known that the sum of normally distributed variables <math id="p3.m1" class="ltx_Math" alttext="X,Y" display="inline"><mrow><mi>X</mi><mo>,</mo><mi>Y</mi></mrow></math> will be normal under either of the following situations.</p>
<ul id="I1" class="ltx_itemize">
<li id="I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_itemize">â€¢</span> 
<div id="I1.i1.p1" class="ltx_para">
<p class="ltx_p"><math id="I1.i1.p1.m1" class="ltx_Math" alttext="X,Y" display="inline"><mrow><mi>X</mi><mo>,</mo><mi>Y</mi></mrow></math> are independent.</p>
</div>
</li>
<li id="I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_itemize">â€¢</span> 
<div id="I1.i2.p1" class="ltx_para">
<p class="ltx_p"><math id="I1.i2.p1.m1" class="ltx_Math" alttext="X,Y" display="inline"><mrow><mi>X</mi><mo>,</mo><mi>Y</mi></mrow></math> are joint normal (<span class="ltx_text ltx_font_typewriter">http://planetmath.org/JointNormalDistribution</span>).</p>
</div>
</li>
</ul>
<p class="ltx_p">The statement that the sum of two independent normal random variables is itself normal is a very useful and often used property. Furthermore, when working with normal variables which are not independent, it is common to suppose that they are in fact joint normal. This can lead to the belief that this property holds always.</p>
</div>
<div id="p4" class="ltx_para">
<p class="ltx_p">Another common fallacy, which our example shows to be false, is that normal random variables are independent if and only if their covariance, defined by</p>
<table id="S0.Ex1" class="ltx_equation ltx_eqn_table">

<tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S0.Ex1.m1" class="ltx_Math" alttext="\operatorname{Cov}(X,Y)\equiv\mathbb{E}[XY]-\mathbb{E}[X]\mathbb{E}[Y]" display="block"><mrow><mrow><mi>Cov</mi><mo>â¡</mo><mrow><mo stretchy="false">(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo stretchy="false">)</mo></mrow></mrow><mo>â‰¡</mo><mrow><mrow><mi>ğ”¼</mi><mo>â¢</mo><mrow><mo stretchy="false">[</mo><mrow><mi>X</mi><mo>â¢</mo><mi>Y</mi></mrow><mo stretchy="false">]</mo></mrow></mrow><mo>-</mo><mrow><mi>ğ”¼</mi><mo>â¢</mo><mrow><mo stretchy="false">[</mo><mi>X</mi><mo stretchy="false">]</mo></mrow><mo>â¢</mo><mi>ğ”¼</mi><mo>â¢</mo><mrow><mo stretchy="false">[</mo><mi>Y</mi><mo stretchy="false">]</mo></mrow></mrow></mrow></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</table>
<p class="ltx_p">is zero. While it is certainly true that independent variables have zero covariance, the converse statement does not hold. Again, it is often supposed that they are joint normal, in which case a zero covariance will indeed imply independence.</p>
</div>
<div id="p5" class="ltx_para">
<p class="ltx_p">We construct a pair of random variables <math id="p5.m1" class="ltx_Math" alttext="X,Y" display="inline"><mrow><mi>X</mi><mo>,</mo><mi>Y</mi></mrow></math> satisfying the following.</p>
<ol id="I2" class="ltx_enumerate">
<li id="I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_enumerate">1.</span> 
<div id="I2.i1.p1" class="ltx_para">
<p class="ltx_p"><math id="I2.i1.p1.m1" class="ltx_Math" alttext="X" display="inline"><mi>X</mi></math> and <math id="I2.i1.p1.m2" class="ltx_Math" alttext="Y" display="inline"><mi>Y</mi></math> each have the standard normal distribution.</p>
</div>
</li>
<li id="I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_enumerate">2.</span> 
<div id="I2.i2.p1" class="ltx_para">
<p class="ltx_p">The covariance, <math id="I2.i2.p1.m1" class="ltx_Math" alttext="\operatorname{Cov}(X,Y)" display="inline"><mrow><mi>Cov</mi><mo>â¡</mo><mrow><mo stretchy="false">(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo stretchy="false">)</mo></mrow></mrow></math>, is zero.</p>
</div>
</li>
<li id="I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_enumerate">3.</span> 
<div id="I2.i3.p1" class="ltx_para">
<p class="ltx_p">The sum <math id="I2.i3.p1.m1" class="ltx_Math" alttext="X+Y" display="inline"><mrow><mi>X</mi><mo>+</mo><mi>Y</mi></mrow></math> is not normally distributed, and <math id="I2.i3.p1.m2" class="ltx_Math" alttext="X" display="inline"><mi>X</mi></math> and <math id="I2.i3.p1.m3" class="ltx_Math" alttext="Y" display="inline"><mi>Y</mi></math> are not independent.</p>
</div>
</li>
</ol>
<p class="ltx_p">We start with a pair of independent random variables <math id="p5.m2" class="ltx_Math" alttext="X,\epsilon" display="inline"><mrow><mi>X</mi><mo>,</mo><mi>Ïµ</mi></mrow></math> where <math id="p5.m3" class="ltx_Math" alttext="X" display="inline"><mi>X</mi></math> has the standard normal distribution and <math id="p5.m4" class="ltx_Math" alttext="\epsilon" display="inline"><mi>Ïµ</mi></math> takes the values <math id="p5.m5" class="ltx_Math" alttext="1,-1" display="inline"><mrow><mn>1</mn><mo>,</mo><mrow><mo>-</mo><mn>1</mn></mrow></mrow></math>, each with a probability of <math id="p5.m6" class="ltx_Math" alttext="1/2" display="inline"><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></math>.
Then set,</p>
<table id="S0.Ex2" class="ltx_equation ltx_eqn_table">

<tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S0.Ex2.m1" class="ltx_Math" alttext="Y=\left\{\begin{array}[]{ll}\epsilon X,&amp;\textrm{if }|X|\leq 1,\\
-\epsilon X,&amp;\textrm{if }|X|&gt;1.\end{array}\right." display="block"><mrow><mi>Y</mi><mo>=</mo><mrow><mo>{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mtr><mtd columnalign="left"><mrow><mrow><mi>Ïµ</mi><mo>â¢</mo><mi>X</mi></mrow><mo>,</mo></mrow></mtd><mtd columnalign="left"><mrow><mrow><mrow><mtext>ifÂ </mtext><mo>â¢</mo><mrow><mo stretchy="false">|</mo><mi>X</mi><mo stretchy="false">|</mo></mrow></mrow><mo>â‰¤</mo><mn>1</mn></mrow><mo>,</mo></mrow></mtd></mtr><mtr><mtd columnalign="left"><mrow><mrow><mo>-</mo><mrow><mi>Ïµ</mi><mo>â¢</mo><mi>X</mi></mrow></mrow><mo>,</mo></mrow></mtd><mtd columnalign="left"><mrow><mrow><mrow><mtext>ifÂ </mtext><mo>â¢</mo><mrow><mo stretchy="false">|</mo><mi>X</mi><mo stretchy="false">|</mo></mrow></mrow><mo>&gt;</mo><mn>1</mn></mrow><mo>.</mo></mrow></mtd></mtr></mtable><mi></mi></mrow></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</table>
<p class="ltx_p">If <math id="p5.m7" class="ltx_Math" alttext="S" display="inline"><mi>S</mi></math> is any measurable subset of the real numbers, the symmetry of the normal distribution implies that <math id="p5.m8" class="ltx_Math" alttext="\mathbb{P}(X\in S)" display="inline"><mrow><mi>â„™</mi><mrow><mo stretchy="false">(</mo><mi>X</mi><mo>âˆˆ</mo><mi>S</mi><mo stretchy="false">)</mo></mrow></mrow></math> is equal to <math id="p5.m9" class="ltx_Math" alttext="\mathbb{P}(-X\in S)" display="inline"><mrow><mi>â„™</mi><mrow><mo stretchy="false">(</mo><mo>-</mo><mi>X</mi><mo>âˆˆ</mo><mi>S</mi><mo stretchy="false">)</mo></mrow></mrow></math>. Then, by the independence of <math id="p5.m10" class="ltx_Math" alttext="X" display="inline"><mi>X</mi></math> and <math id="p5.m11" class="ltx_Math" alttext="\epsilon" display="inline"><mi>Ïµ</mi></math>, the distribution of <math id="p5.m12" class="ltx_Math" alttext="Y" display="inline"><mi>Y</mi></math> conditional on <math id="p5.m13" class="ltx_Math" alttext="\epsilon=1" display="inline"><mrow><mi>Ïµ</mi><mo>=</mo><mn>1</mn></mrow></math> is given by,</p>
<table id="S0.Ex3" class="ltx_equation ltx_eqn_table">

<tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S0.Ex3.m1" class="ltx_Math" alttext="\begin{split}\displaystyle\mathbb{P}(Y\in S\mid\epsilon=1)&amp;\displaystyle=%
\mathbb{P}(|X|\leq 1,X\in S)+\mathbb{P}(|X|&gt;1,-X\in S)\\
&amp;\displaystyle=\mathbb{P}(|X|\leq 1,X\in S)+\mathbb{P}(|X|&gt;1,X\in S)=\mathbb{P%
}(X\in S).\end{split}" display="block"><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt"><mtr><mtd columnalign="right"><mrow><mi>â„™</mi><mrow><mo stretchy="false">(</mo><mi>Y</mi><mo>âˆˆ</mo><mi>S</mi><mo>âˆ£</mo><mi>Ïµ</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mrow></mtd><mtd columnalign="left"><mrow><mo>=</mo><mi>â„™</mi><mrow><mo stretchy="false">(</mo><mo stretchy="false">|</mo><mi>X</mi><mo stretchy="false">|</mo><mo>â‰¤</mo><mn>1</mn><mo>,</mo><mi>X</mi><mo>âˆˆ</mo><mi>S</mi><mo stretchy="false">)</mo></mrow><mo>+</mo><mi>â„™</mi><mrow><mo stretchy="false">(</mo><mo stretchy="false">|</mo><mi>X</mi><mo stretchy="false">|</mo><mo>&gt;</mo><mn>1</mn><mo>,</mo><mo>-</mo><mi>X</mi><mo>âˆˆ</mo><mi>S</mi><mo stretchy="false">)</mo></mrow></mrow></mtd></mtr><mtr><mtd></mtd><mtd columnalign="left"><mrow><mo>=</mo><mi>â„™</mi><mrow><mo stretchy="false">(</mo><mo stretchy="false">|</mo><mi>X</mi><mo stretchy="false">|</mo><mo>â‰¤</mo><mn>1</mn><mo>,</mo><mi>X</mi><mo>âˆˆ</mo><mi>S</mi><mo stretchy="false">)</mo></mrow><mo>+</mo><mi>â„™</mi><mrow><mo stretchy="false">(</mo><mo stretchy="false">|</mo><mi>X</mi><mo stretchy="false">|</mo><mo>&gt;</mo><mn>1</mn><mo>,</mo><mi>X</mi><mo>âˆˆ</mo><mi>S</mi><mo stretchy="false">)</mo></mrow><mo>=</mo><mi>â„™</mi><mrow><mo stretchy="false">(</mo><mi>X</mi><mo>âˆˆ</mo><mi>S</mi><mo stretchy="false">)</mo></mrow><mo>.</mo></mrow></mtd></mtr></mtable></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</table>
<p class="ltx_p">It can similarly be shown that <math id="p5.m14" class="ltx_Math" alttext="\mathbb{P}(Y\in S\mid\epsilon=-1)" display="inline"><mrow><mi>â„™</mi><mrow><mo stretchy="false">(</mo><mi>Y</mi><mo>âˆˆ</mo><mi>S</mi><mo>âˆ£</mo><mi>Ïµ</mi><mo>=</mo><mo>-</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mrow></math> is equal to <math id="p5.m15" class="ltx_Math" alttext="\mathbb{P}(X\in S)" display="inline"><mrow><mi>â„™</mi><mrow><mo stretchy="false">(</mo><mi>X</mi><mo>âˆˆ</mo><mi>S</mi><mo stretchy="false">)</mo></mrow></mrow></math>.
So, <math id="p5.m16" class="ltx_Math" alttext="Y" display="inline"><mi>Y</mi></math> has the same distribution as <math id="p5.m17" class="ltx_Math" alttext="X" display="inline"><mi>X</mi></math> and is normal with mean zero and variance one.</p>
</div>
<div id="p6" class="ltx_para">
<p class="ltx_p">Using the fact that <math id="p6.m1" class="ltx_Math" alttext="\epsilon" display="inline"><mi>Ïµ</mi></math> has zero mean and is independent of <math id="p6.m2" class="ltx_Math" alttext="X" display="inline"><mi>X</mi></math>, it is easily shown that the covariance of <math id="p6.m3" class="ltx_Math" alttext="X" display="inline"><mi>X</mi></math> and <math id="p6.m4" class="ltx_Math" alttext="Y" display="inline"><mi>Y</mi></math> is zero.</p>
<table id="S0.Ex4" class="ltx_equation ltx_eqn_table">

<tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S0.Ex4.m1" class="ltx_Math" alttext="\begin{split}\displaystyle\operatorname{Cov}(X,Y)&amp;\displaystyle=\mathbb{E}[XY]%
-\mathbb{E}[X]\mathbb{E}[Y]=\mathbb{E}[XY]\\
&amp;\displaystyle=\mathbb{E}\left[1_{\{|X|\leq 1\}}\epsilon X^{2}\right]+\mathbb{%
E}\left[-1_{\{|X|&gt;1\}}\epsilon X^{2}\right]\\
&amp;\displaystyle=\mathbb{E}[\epsilon]\mathbb{E}\left[1_{\{|X|\leq 1\}}X^{2}%
\right]-\mathbb{E}[\epsilon]\mathbb{E}\left[1_{\{|X|&gt;1\}}X^{2}\right]\\
&amp;\displaystyle=0.\end{split}" display="block"><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt"><mtr><mtd columnalign="right"><mrow><mi>Cov</mi><mo>â¡</mo><mrow><mo stretchy="false">(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo stretchy="false">)</mo></mrow></mrow></mtd><mtd columnalign="left"><mrow><mi></mi><mo>=</mo><mrow><mrow><mi>ğ”¼</mi><mo>â¢</mo><mrow><mo stretchy="false">[</mo><mrow><mi>X</mi><mo>â¢</mo><mi>Y</mi></mrow><mo stretchy="false">]</mo></mrow></mrow><mo>-</mo><mrow><mi>ğ”¼</mi><mo>â¢</mo><mrow><mo stretchy="false">[</mo><mi>X</mi><mo stretchy="false">]</mo></mrow><mo>â¢</mo><mi>ğ”¼</mi><mo>â¢</mo><mrow><mo stretchy="false">[</mo><mi>Y</mi><mo stretchy="false">]</mo></mrow></mrow></mrow><mo>=</mo><mrow><mi>ğ”¼</mi><mo>â¢</mo><mrow><mo stretchy="false">[</mo><mrow><mi>X</mi><mo>â¢</mo><mi>Y</mi></mrow><mo stretchy="false">]</mo></mrow></mrow></mrow></mtd></mtr><mtr><mtd></mtd><mtd columnalign="left"><mrow><mi></mi><mo>=</mo><mrow><mrow><mi>ğ”¼</mi><mo>â¢</mo><mrow><mo>[</mo><mrow><msub><mn>1</mn><mrow><mo stretchy="false">{</mo><mo stretchy="false">|</mo><mi>X</mi><mo stretchy="false">|</mo><mo>â‰¤</mo><mn>1</mn><mo stretchy="false">}</mo></mrow></msub><mo>â¢</mo><mi>Ïµ</mi><mo>â¢</mo><msup><mi>X</mi><mn>2</mn></msup></mrow><mo>]</mo></mrow></mrow><mo>+</mo><mrow><mi>ğ”¼</mi><mo>â¢</mo><mrow><mo>[</mo><mrow><mo>-</mo><mrow><msub><mn>1</mn><mrow><mo stretchy="false">{</mo><mo stretchy="false">|</mo><mi>X</mi><mo stretchy="false">|</mo><mo>&gt;</mo><mn>1</mn><mo stretchy="false">}</mo></mrow></msub><mo>â¢</mo><mi>Ïµ</mi><mo>â¢</mo><msup><mi>X</mi><mn>2</mn></msup></mrow></mrow><mo>]</mo></mrow></mrow></mrow></mrow></mtd></mtr><mtr><mtd></mtd><mtd columnalign="left"><mrow><mi></mi><mo>=</mo><mrow><mrow><mi>ğ”¼</mi><mo>â¢</mo><mrow><mo stretchy="false">[</mo><mi>Ïµ</mi><mo stretchy="false">]</mo></mrow><mo>â¢</mo><mi>ğ”¼</mi><mo>â¢</mo><mrow><mo>[</mo><mrow><msub><mn>1</mn><mrow><mo stretchy="false">{</mo><mo stretchy="false">|</mo><mi>X</mi><mo stretchy="false">|</mo><mo>â‰¤</mo><mn>1</mn><mo stretchy="false">}</mo></mrow></msub><mo>â¢</mo><msup><mi>X</mi><mn>2</mn></msup></mrow><mo>]</mo></mrow></mrow><mo>-</mo><mrow><mi>ğ”¼</mi><mo>â¢</mo><mrow><mo stretchy="false">[</mo><mi>Ïµ</mi><mo stretchy="false">]</mo></mrow><mo>â¢</mo><mi>ğ”¼</mi><mo>â¢</mo><mrow><mo>[</mo><mrow><msub><mn>1</mn><mrow><mo stretchy="false">{</mo><mo stretchy="false">|</mo><mi>X</mi><mo stretchy="false">|</mo><mo>&gt;</mo><mn>1</mn><mo stretchy="false">}</mo></mrow></msub><mo>â¢</mo><msup><mi>X</mi><mn>2</mn></msup></mrow><mo>]</mo></mrow></mrow></mrow></mrow></mtd></mtr><mtr><mtd></mtd><mtd columnalign="left"><mrow><mrow><mi></mi><mo>=</mo><mn>0</mn></mrow><mo>.</mo></mrow></mtd></mtr></mtable></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</table>
<p class="ltx_p">As <math id="p6.m5" class="ltx_Math" alttext="X" display="inline"><mi>X</mi></math> and <math id="p6.m6" class="ltx_Math" alttext="Y" display="inline"><mi>Y</mi></math> have zero covariance and each have variance equal to <math id="p6.m7" class="ltx_Math" alttext="1" display="inline"><mn>1</mn></math>, the sum <math id="p6.m8" class="ltx_Math" alttext="X+Y" display="inline"><mrow><mi>X</mi><mo>+</mo><mi>Y</mi></mrow></math> will have variance equal to <math id="p6.m9" class="ltx_Math" alttext="2" display="inline"><mn>2</mn></math>. Also, the sum satisfies</p>
<table id="S0.Ex5" class="ltx_equation ltx_eqn_table">

<tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S0.Ex5.m1" class="ltx_Math" alttext="X+Y=\left\{\begin{array}[]{ll}2\epsilon X,&amp;\textrm{if }|X|\leq 1,\\
0,&amp;\textrm{if }|X|&gt;1.\end{array}\right." display="block"><mrow><mrow><mi>X</mi><mo>+</mo><mi>Y</mi></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mtr><mtd columnalign="left"><mrow><mrow><mn>2</mn><mo>â¢</mo><mi>Ïµ</mi><mo>â¢</mo><mi>X</mi></mrow><mo>,</mo></mrow></mtd><mtd columnalign="left"><mrow><mrow><mrow><mtext>ifÂ </mtext><mo>â¢</mo><mrow><mo stretchy="false">|</mo><mi>X</mi><mo stretchy="false">|</mo></mrow></mrow><mo>â‰¤</mo><mn>1</mn></mrow><mo>,</mo></mrow></mtd></mtr><mtr><mtd columnalign="left"><mrow><mn>0</mn><mo>,</mo></mrow></mtd><mtd columnalign="left"><mrow><mrow><mrow><mtext>ifÂ </mtext><mo>â¢</mo><mrow><mo stretchy="false">|</mo><mi>X</mi><mo stretchy="false">|</mo></mrow></mrow><mo>&gt;</mo><mn>1</mn></mrow><mo>.</mo></mrow></mtd></mtr></mtable><mi></mi></mrow></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</table>
<p class="ltx_p">In particular, this shows that <math id="p6.m10" class="ltx_Math" alttext="\mathbb{P}(|X+Y|&gt;2)=0" display="inline"><mrow><mi>â„™</mi><mrow><mo stretchy="false">(</mo><mo stretchy="false">|</mo><mi>X</mi><mo>+</mo><mi>Y</mi><mo stretchy="false">|</mo><mo>&gt;</mo><mn>2</mn><mo stretchy="false">)</mo></mrow><mo>=</mo><mn>0</mn></mrow></math>. However, normal random variables with nonzero variance always have a positive probability of being greater than any given real number. So, <math id="p6.m11" class="ltx_Math" alttext="X+Y" display="inline"><mrow><mi>X</mi><mo>+</mo><mi>Y</mi></mrow></math> is not normally distributed.</p>
</div>
<div id="p7" class="ltx_para">
<p class="ltx_p">This also shows that, despite having zero covariance, <math id="p7.m1" class="ltx_Math" alttext="X" display="inline"><mi>X</mi></math> and <math id="p7.m2" class="ltx_Math" alttext="Y" display="inline"><mi>Y</mi></math> are not independent. If they were, then the fact that sums of independent normals are normal would imply that <math id="p7.m3" class="ltx_Math" alttext="X+Y" display="inline"><mrow><mi>X</mi><mo>+</mo><mi>Y</mi></mrow></math> is normal, contradicting what we have just demonstrated.</p>
</div>
<div id="p8" class="ltx_para ltx_align_right">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_t">Title</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">sums of normal random variables need not be normal</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l">Canonical name</th>
<td class="ltx_td ltx_align_left ltx_border_r">SumsOfNormalRandomVariablesNeedNotBeNormal</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l">Date of creation</th>
<td class="ltx_td ltx_align_left ltx_border_r">2013-03-22 18:43:44</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l">Last modified on</th>
<td class="ltx_td ltx_align_left ltx_border_r">2013-03-22 18:43:44</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l">Owner</th>
<td class="ltx_td ltx_align_left ltx_border_r">gel (22282)</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l">Last modified by</th>
<td class="ltx_td ltx_align_left ltx_border_r">gel (22282)</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l">Numerical id</th>
<td class="ltx_td ltx_align_left ltx_border_r">5</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l">Author</th>
<td class="ltx_td ltx_align_left ltx_border_r">gel (22282)</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l">Entry type</th>
<td class="ltx_td ltx_align_left ltx_border_r">Example</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l">Classification</th>
<td class="ltx_td ltx_align_left ltx_border_r">msc 62E15</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l">Classification</th>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r">msc 60E05</td>
</tr>
</tbody>
</table>
</div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sat Feb 10 12:04:17 2018 by <a href="http://dlmf.nist.gov/LaTeXML/">LaTeXML <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"></a>
</div></footer>
</div>
</body>
</html>
